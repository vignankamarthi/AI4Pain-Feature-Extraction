#!/usr/bin/env python3
"""
AI4PAIN Feature Visualization
-----------------------------
Visualizes and analyzes feature tables generated by the feature extraction process.
Focuses on key relationships between permutation entropy, complexity, and pain states.

Usage:
    python view_results.py [--file PATH_TO_CSV]
"""

import argparse
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

def load_feature_data(file_path="results/features_complete.csv"):
    """
    Load feature data from CSV file and standardize pain states.
    
    Parameters
    ----------
    file_path : str, optional
        Path to the CSV file containing feature data.
        
    Returns
    -------
    pandas.DataFrame
        DataFrame containing the feature data with standardized pain states.
    """
    if not os.path.exists(file_path):
        print(f"Error: File not found: {file_path}")
        return None
    
    try:
        df = pd.read_csv(file_path)
        print(f"Loaded data with {len(df)} rows from {file_path}")
        
        # Standardize pain states - map "baseline" and "rest" to "no pain"
        df['original_state'] = df['state'].copy()  # Preserve original state
        df['state'] = df['state'].str.lower()  # Convert to lowercase for consistent mapping
        df['state'] = df['state'].replace(['baseline', 'rest'], 'no pain')
        
        print(f"Standardized pain states: {df['state'].unique().tolist()}")
        
        return df
    except Exception as e:
        print(f"Error loading data: {str(e)}")
        return None
def display_dataframe(df, num_rows=10):
    """
    Display a simple preview of the DataFrame in the terminal.
    This function is left for compatibility but doesn't output to terminal.
    For proper DataFrame viewing, use view_dataframe.py instead.
    
    Parameters
    ----------
    df : pandas.DataFrame
        The DataFrame to display.
    num_rows : int, optional
        Number of rows to display from start and end.
    """
    # This function is intentionally empty
    pass

def show_data_summary(df):
    """
    Generate summary statistics for the feature data.
    
    Parameters
    ----------
    df : pandas.DataFrame
        DataFrame containing the feature data.
    """
    print("\n=== Data Statistics ===\n")
    
    # Log basic information without displaying tables
    print(f"Total samples: {len(df)}")
    
    # Count by signal type
    print("\nSamples by signal type:")
    for signal_type, count in df['signal_type'].value_counts().items():
        print(f"  {signal_type}: {count}")
    
    # Count by state
    print("\nSamples by pain state:")
    for state, count in df['state'].value_counts().items():
        print(f"  {state}: {count}")
    
    # Basic statistics for key metrics (without displaying tables)
    for column in ['pe', 'comp', 'fisher']:
        stats = df[column].describe()
        print(f"\n{column.upper()} statistics:")
        print(f"  Mean: {stats['mean']:.6f}")
        print(f"  Std: {stats['std']:.6f}")
        print(f"  Min: {stats['min']:.6f}")
        print(f"  Max: {stats['max']:.6f}")

def plot_complexity_entropy(df):
    """
    Create complexity-entropy causality plane scatter plot.
    
    Parameters
    ----------
    df : pandas.DataFrame
        DataFrame containing the feature data.
    """
    plt.figure(figsize=(24, 20))
    
    # Create color map for states
    states = df['state'].unique()
    state_colors = {
        'no pain': 'blue',
        'low': 'green',
        'high': 'red'
    }
    
    # Fill in any missing states with default colors
    for state in states:
        if state not in state_colors:
            state_colors[state] = 'gray'
    
    # Create marker map for signal types
    signal_types = df['signal_type'].unique()
    markers = ['.', '+', '*', 'x', 'o', 's', '^', 'd']  # Use dot and plus as first choices - they render smaller
    signal_markers = {signal_type: markers[i % len(markers)] for i, signal_type in enumerate(signal_types)}
    
    # Create subplots for each dimension-tau combination
    dims = sorted(df['dimension'].unique())
    taus = sorted(df['tau'].unique())
    
    # Calculate number of subplots needed
    num_subplots = len(dims) * len(taus)
    rows = int(np.ceil(np.sqrt(num_subplots)))
    cols = int(np.ceil(num_subplots / rows))
    
    # Adjust subplot parameters for better spacing
    plt.subplots_adjust(wspace=0.4, hspace=0.4)
    
    # Set up legend handles and labels
    legend_handles = []
    legend_labels = []
    
    # Create plots for each dimension-tau combination
    for i, dim in enumerate(dims):
        for j, tau in enumerate(taus):
            subplot_idx = i * len(taus) + j + 1
            if subplot_idx <= num_subplots:
                ax = plt.subplot(rows, cols, subplot_idx)
                
                # Filter data for this dimension-tau combination
                subset = df[(df['dimension'] == dim) & (df['tau'] == tau)]
                
                # Plot each signal type and state combination
                for signal_type in signal_types:
                    signal_subset = subset[subset['signal_type'] == signal_type]
                    
                    for state in states:
                        data = signal_subset[signal_subset['state'] == state]
                        
                        if len(data) > 0:
                            scatter = ax.scatter(data['pe'], data['comp'], 
                                       c=state_colors.get(state, 'gray'),
                                       marker=signal_markers.get(signal_type, 'x'),
                                       alpha=0.7,
                                       s=12,  # Slightly larger marker size
                                       label=f"{signal_type} - {state}")
                            
                            # Add to legend only once
                            if f"{signal_type} - {state}" not in legend_labels:
                                legend_handles.append(scatter)
                                legend_labels.append(f"{signal_type} - {state}")
                
                # Add reference curve (theoretical min/max complexity for given entropy)
                x = np.linspace(0.01, 0.99, 100)  # Avoid 0 and 1 for log calculations
                y_max = -x * np.log2(x) - (1-x) * np.log2(1-x)  # Theoretical maximum curve
                y_max = y_max / np.max(y_max) * 0.5  # Scale to match typical complexity range
                ax.plot(x, y_max, 'k--', alpha=0.3)
                
                ax.set_xlabel('Permutation Entropy (PE)', fontsize=12)
                ax.set_ylabel('Complexity (COMP)', fontsize=12)
                ax.set_title(f'Dimension = {dim}, Tau = {tau}', fontsize=14)
                ax.grid(True, alpha=0.3)
                ax.set_xlim(0, 1.05)
                ax.set_ylim(0, 0.6)
                ax.tick_params(axis='both', which='major', labelsize=10)
                for spine in ax.spines.values():
                    spine.set_linewidth(1.5)
    
    # Add a single legend for the entire figure
    fig = plt.gcf()
    # Create a more attractive legend with larger symbol size
    fig.legend(legend_handles, legend_labels, loc='upper center', bbox_to_anchor=(0.5, 0.05),
               ncol=min(5, len(legend_labels)), frameon=True, fancybox=True, shadow=True, fontsize=12,
               borderpad=1.0, labelspacing=0.7, handletextpad=0.5, markerscale=2.0)
    
    plt.suptitle('Complexity-Entropy Causality Plane', fontsize=22, y=0.98)
    plt.tight_layout(rect=[0, 0.07, 1, 0.96])  # Make a bit more room for the legend
    plt.savefig('results/complexity_entropy_plane.png', dpi=600, bbox_inches='tight')
    plt.close()

def analyze_state_transitions(df):
    """
    Analyze changes in metrics between pain states.
    
    Parameters
    ----------
    df : pandas.DataFrame
        DataFrame containing the feature data.
        
    Returns
    -------
    tuple of pandas.DataFrame
        Pivoted DataFrames with PE, complexity, and Fisher values and changes.
    """
    # Check if we have multiple states to compare
    states = df['state'].unique()
    if len(states) < 2:
        print("\n=== State Transition Analysis ===\n")
        print("Not enough pain states to perform transition analysis.")
        return None, None, None
    
    # Group by relevant factors and calculate mean for each state
    grouped = df.groupby(['signal_type', 'dimension', 'tau', 'state'])[['pe', 'comp', 'fisher']].mean().reset_index()
    
    # Pivot to get states as columns
    pivot_pe = pd.pivot_table(grouped, values='pe', index=['signal_type', 'dimension', 'tau'], 
                             columns='state')
    pivot_comp = pd.pivot_table(grouped, values='comp', index=['signal_type', 'dimension', 'tau'], 
                               columns='state')
    pivot_fisher = pd.pivot_table(grouped, values='fisher', index=['signal_type', 'dimension', 'tau'], 
                               columns='state')
    
    # Order states from no pain to high pain
    ordered_states = []
    if 'no pain' in states:
        ordered_states.append('no pain')
    if 'low' in states:
        ordered_states.append('low')
    if 'high' in states:
        ordered_states.append('high')
    
    # Add any other states at the end
    for state in states:
        if state not in ordered_states:
            ordered_states.append(state)
    
    print("\n=== State Transition Analysis ===\n")
    print(f"Analyzing transitions between states: {ordered_states}")
    
    # Calculate changes between consecutive states
    if len(ordered_states) >= 2:
        for i in range(len(ordered_states)-1):
            state1 = ordered_states[i]
            state2 = ordered_states[i+1]
            
            if state1 in pivot_pe.columns and state2 in pivot_pe.columns:
                col_name = f'change_{state1}_to_{state2}'
                pivot_pe[col_name] = pivot_pe[state2] - pivot_pe[state1]
                pivot_comp[col_name] = pivot_comp[state2] - pivot_comp[state1]
                pivot_fisher[col_name] = pivot_fisher[state2] - pivot_fisher[state1]
                
                print(f"\nChanges from {state1} to {state2}:")
                print(f"  PE: Mean change = {pivot_pe[col_name].mean():.6f}")
                print(f"  Complexity: Mean change = {pivot_comp[col_name].mean():.6f}")
                print(f"  Fisher: Mean change = {pivot_fisher[col_name].mean():.6f}")
    
    # If we have at least 3 states, also calculate no pain to high
    if len(ordered_states) >= 3 and ordered_states[0] in pivot_pe.columns and ordered_states[-1] in pivot_pe.columns:
        col_name = f'change_{ordered_states[0]}_to_{ordered_states[-1]}'
        pivot_pe[col_name] = pivot_pe[ordered_states[-1]] - pivot_pe[ordered_states[0]]
        pivot_comp[col_name] = pivot_comp[ordered_states[-1]] - pivot_comp[ordered_states[0]]
        pivot_fisher[col_name] = pivot_fisher[ordered_states[-1]] - pivot_fisher[ordered_states[0]]
        
        print(f"\nOverall changes from {ordered_states[0]} to {ordered_states[-1]}:")
        print(f"  PE: Mean change = {pivot_pe[col_name].mean():.6f}")
        print(f"  Complexity: Mean change = {pivot_comp[col_name].mean():.6f}")
        print(f"  Fisher: Mean change = {pivot_fisher[col_name].mean():.6f}")
    
    # Skip displaying pivot tables in terminal
    
    # Create visual representation of changes
    change_cols_pe = [col for col in pivot_pe.columns if 'change' in col]
    change_cols_comp = [col for col in pivot_comp.columns if 'change' in col]
    change_cols_fisher = [col for col in pivot_fisher.columns if 'change' in col]
    
    if change_cols_pe:
        plt.figure(figsize=(15, 15))
        
        # Plot PE changes
        plt.subplot(3, 1, 1)
        pivot_pe[change_cols_pe].plot(kind='bar', ax=plt.gca())
        plt.title('Changes in Permutation Entropy Between Pain States')
        plt.ylabel('Change in PE')
        plt.xticks(rotation=45, ha='right')
        plt.grid(True, alpha=0.3)
        
        # Plot Complexity changes
        plt.subplot(3, 1, 2)
        pivot_comp[change_cols_comp].plot(kind='bar', ax=plt.gca())
        plt.title('Changes in Complexity Between Pain States')
        plt.ylabel('Change in Complexity')
        plt.xticks(rotation=45, ha='right')
        plt.grid(True, alpha=0.3)
        
        # Plot Fisher changes
        plt.subplot(3, 1, 3)
        pivot_fisher[change_cols_fisher].plot(kind='bar', ax=plt.gca())
        plt.title('Changes in Fisher Information Between Pain States')
        plt.ylabel('Change in Fisher')
        plt.xticks(rotation=45, ha='right')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('results/state_transitions.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    return pivot_pe, pivot_comp, pivot_fisher

def evaluate_parameter_effectiveness(pivot_pe, pivot_comp, pivot_fisher):
    """
    Evaluate which parameter combinations (dimension, tau) are most effective.
    
    Parameters
    ----------
    pivot_pe : pandas.DataFrame
        Pivoted DataFrame with PE changes.
    pivot_comp : pandas.DataFrame
        Pivoted DataFrame with complexity changes.
    pivot_fisher : pandas.DataFrame
        Pivoted DataFrame with Fisher changes.
    """
    if pivot_pe is None or pivot_comp is None or pivot_fisher is None:
        print("\n=== Parameter Effectiveness ===\n")
        print("Cannot evaluate parameter effectiveness without state transition data.")
        return
    
    # Combine PE and complexity changes for overall effectiveness score
    effectiveness = pd.DataFrame(index=pivot_pe.index)
    
    # Get change columns
    pe_change_cols = [col for col in pivot_pe.columns if 'change' in col]
    comp_change_cols = [col for col in pivot_comp.columns if 'change' in col]
    fisher_change_cols = [col for col in pivot_fisher.columns if 'change' in col]
    
    if not pe_change_cols and not comp_change_cols and not fisher_change_cols:
        print("\n=== Parameter Effectiveness ===\n")
        print("No state transitions found for parameter effectiveness evaluation.")
        return
    
    # Calculate absolute changes (magnitude matters, not direction)
    for col in pe_change_cols:
        effectiveness[f'abs_pe_{col}'] = pivot_pe[col].abs()
    
    for col in comp_change_cols:
        effectiveness[f'abs_comp_{col}'] = pivot_comp[col].abs()
        
    for col in fisher_change_cols:
        effectiveness[f'abs_fisher_{col}'] = pivot_fisher[col].abs()
    
    # Calculate overall effectiveness score (sum of absolute changes)
    effectiveness['total_score'] = effectiveness.sum(axis=1)
    
    # Sort by total score (descending)
    effectiveness = effectiveness.sort_values('total_score', ascending=False)
    
    print("\n=== Parameter Effectiveness ===\n")
    
    # Print top parameters without detailed table
    print("Most effective parameter combinations:")
    top_params = effectiveness.head(5).reset_index()
    for i, row in top_params.iterrows():
        print(f"  {i+1}. Signal: {row['signal_type']}, Dimension: {row['dimension']}, Tau: {row['tau']}, Score: {row['total_score']:.6f}")
    
    # Create a table showing the best parameters for each signal type
    best_params = effectiveness.reset_index().groupby('signal_type')['total_score'].idxmax()
    best_params = effectiveness.reset_index().iloc[best_params]
    
    print("\nBest parameters for each signal type:")
    for _, row in best_params.iterrows():
        print(f"  {row['signal_type']}: dimension={row['dimension']}, tau={row['tau']}, score={row['total_score']:.6f}")
    
    # Visualize parameter effectiveness
    plt.figure(figsize=(12, 10))
    
    # Extract dimension and tau for plotting
    effectiveness_reset = effectiveness.reset_index()
    
    # Group by dimension and tau, then calculate mean score across signal types
    dim_tau_scores = effectiveness_reset.groupby(['dimension', 'tau'])['total_score'].mean().reset_index()
    pivot_scores = dim_tau_scores.pivot(index='dimension', columns='tau', values='total_score')
    
    # Create heatmap
    plt.subplot(2, 1, 1)
    sns.heatmap(pivot_scores, annot=True, cmap='viridis', fmt='.4f')
    plt.title('Overall Parameter Effectiveness (Higher = Better at Distinguishing Pain States)')
    plt.xlabel('Tau (Time Delay)')
    plt.ylabel('Dimension')
    
    # Create bar chart for signal types
    plt.subplot(2, 1, 2)
    signal_scores = effectiveness_reset.groupby('signal_type')['total_score'].mean().sort_values(ascending=False)
    signal_scores.plot(kind='bar')
    plt.title('Signal Type Effectiveness')
    plt.xlabel('Signal Type')
    plt.ylabel('Effectiveness Score')
    plt.xticks(rotation=45, ha='right')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('results/parameter_effectiveness.png', dpi=300, bbox_inches='tight')
    plt.close()

def main():
    """Main function to load data and run analysis."""
    # Parse command line arguments
    parser = argparse.ArgumentParser(description='AI4PAIN Feature Visualization')
    parser.add_argument('--file', type=str, default='results/features_complete.csv',
                        help='Path to the CSV file containing feature data')
    args = parser.parse_args()
    
    # Load data
    df = load_feature_data(args.file)
    if df is None:
        return
    
    # Display DataFrame (first step as requested)
    display_dataframe(df)
    
    # Show data summary
    show_data_summary(df)
    
    # Plot complexity-entropy plane
    plot_complexity_entropy(df)
    
    # Analyze state transitions
    pivot_pe, pivot_comp, pivot_fisher = analyze_state_transitions(df)
    
    # Evaluate parameter effectiveness
    evaluate_parameter_effectiveness(pivot_pe, pivot_comp, pivot_fisher)
    
    print("\nAnalysis complete. Visualization images saved to the results directory:")
    print("  - results/complexity_entropy_plane.png")
    print("  - results/state_transitions.png")
    print("  - results/parameter_effectiveness.png")

if __name__ == "__main__":
    # Set Seaborn style for prettier plots
    sns.set_theme(style="whitegrid")
    
    # Make sure the results directory exists
    os.makedirs("results", exist_ok=True)
    
    main()
